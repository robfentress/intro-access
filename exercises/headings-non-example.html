<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Screen reader</title>
    <style>
        html,
        body {
            font-family: sans-serif;
        }

        .level1,
        .level2 {
            border-bottom: 1px solid #a2a9b1;
            font-family: 'Linux Libertine', 'Georgia', 'Times', serif;
        }

        .level1 {
            font-size: 1.8em;
        }

        .level2 {
            font-size: 1.5em;
        }

        .level3 {
            font-size: 1.3em;
            font-weight: bold;
        }

        .level4 {
            font-weight: bold;
        }
    </style>
</head>

<body>
    <p class="level1">Screen reader</p>
    <p>
        From Wikipedia, the free encyclopedia
    </p>
    <p>A screen reader is a form of assistive technology (AT) that renders text and image content as speech or Braille
        output. Screen readers are essential to people who are blind, and are useful to people who are visually
        impaired, illiterate, or have a
        learning disability. Screen readers are software applications that attempt to convey what people with normal
        eyesight see on a display to their users via non-visual means, like text-to-speech, sound icons, or a Braille
        device. They do this by
        applying a wide variety of techniques that include, for example, interacting with dedicated accessibility APIs,
        using various operating system features (like inter-process communication and querying user interface
        properties), and employing hooking
        techniques.
    </p>
    <p>Microsoft Windows operating systems have included the Microsoft Narrator screen reader since Windows 2000, though
        separate products such as the free and open source screen reader NVDA by NV Access and Freedom Scientific's
        commercially available JAWS
        screen reader and ZoomText screen magnifier are more popular for that operating system. Apple Inc.'s macOS, iOS,
        and tvOS include VoiceOver as a built-in screen reader, while Google's Android provides the Talkback screen
        reader and its Chrome
        OS can use ChromeVox. Similarly, Android-based devices from Amazon provide the VoiceView screen reader. There
        are also free and open source screen readers for Linux and Unix-like systems, such as Speakup and Orca.</p>
    <p class="level2">
        Types
    </p>
    <p class="level3">
        Command-line (text)
    </p>
    <p>
        In early operating systems, such as MS-DOS, which employed command-line interfaces (CLIs), the screen display
        consisted of characters mapping directly to a screen buffer in memory and a cursor position. Input was by
        keyboard. All this information could
        therefore be obtained from the system either by hooking the flow of information around the system and reading
        the screen buffer or by using a standard hardware output socket and communicating the results to the user.
    </p>

    <p>
        In the 1980s, the Research Centre for the Education of the Visually Handicapped (RCEVH) at the University of
        Birmingham developed Screen Reader for the BBC Micro and NEC Portable.
    </p>

    <p class="level3">
        Graphical
    </p>
    <p class="level4">
        Off-screen models
    </p>
    <p>
        With the arrival of graphical user interfaces (GUIs), the situation became more complicated. A GUI has
        characters and graphics drawn on the screen at particular positions, and therefore there is no purely textual
        representation of the graphical contents
        of the display. Screen readers were therefore forced to see employ new low-level techniques, gathering messages
        from the operating system and using these to build up an "off-screen model", a representation of the display in
        which the required
        text content is stored.
    </p>

    <p>
        For example, the operating system might send messages to draw a command button and its caption. These messages
        are intercepted and used to construct the off-screen model. The user can switch between controls (such as
        buttons) available on the screen and
        the captions and control contents will be read aloud and/or shown on refreshable Braille display.
    </p>

    <p>
        Screen readers can also communicate information on menus, controls, and other visual constructs to permit blind
        users to interact with these constructs. However, maintaining an off-screen model is a significant technical
        challenge; hooking the low-level
        messages and maintaining an accurate model are both difficult tasks.
    </p>

    <p class="level4">
        Accessibility APIs
    </p>
    <p>
        Operating system and application designers have attempted to address these problems by providing ways for screen
        readers to access the display contents without having to maintain an off-screen model. These involve the
        provision of alternative and accessible
        representations of what is being displayed on the screen accessed through an API. Existing APIs include:
    </p>

    <ul>
        <li>
            Android Accessibility Framework
        </li>
        <li>
            Apple Accessibility API
        </li>
        <li>
            AT-SPI
        </li>
        <li>
            IAccessible2
        </li>
        <li>
            Microsoft Active Accessibility (MSAA)
        </li>
        <li>
            Microsoft UI Automation
        </li>
        <li>
            Java Access Bridge
        </li>
    </ul>
    <p>
        Screen readers can query the operating system or application for what is currently being displayed and receive
        updates when the display changes. For example, a screen reader can be told that the current focus is on a button
        and the button caption to be
        communicated to the user. This approach is considerably easier for the developers of screen readers, but fails
        when applications do not comply with the accessibility API: for example, Microsoft Word does not comply with the
        MSAA API, so screen
        readers must still maintain an off-screen model for Word or find another way to access its contents. One
        approach is to use available operating system messages and application object models to supplement accessibility
        APIs.
    </p>

    <p>
        Screen readers can be assumed to be able to access all display content that is not intrinsically inaccessible.
        Web browsers, word processors, icons and windows and email programs are just some of the applications used
        successfully by screen reader users.
        However, according to some users, using a screen reader is considerably more difficult than using a GUI, and
        many applications have specific problems resulting from the nature of the application (e.g. animations) or
        failure to comply with accessibility
        standards for the platform (e.g. Microsoft Word and Active Accessibility).
    </p>

    <h3 class="level3">
        Self-voicing programs and applications
    </h3>
    <p>
        Some programs and applications have voicing technology built in alongside their primary functionality. These
        programs are termed self-voicing and can be a form of assistive technology if they are designed to remove the
        need to use a screen reader.
    </p>

    <h3 class="level3">
        Cloud-based
    </h3>
    <p>
        Some telephone services allow users to interact with the internet remotely. For example, TeleTender can read web
        pages over the phone and does not require special programs or devices on the user side.
    </p>

    <h3 class="level3">
        Web-based
    </h3>
    <p>
        A relatively new development in the field is web-based applications like Spoken-Web that act as web portals,
        managing content like news updates, weather, science and business articles for visually-impaired or blind
        computer users. Other examples are ReadSpeaker
        or BrowseAloud that add text-to-speech functionality to web content. The primary audience for such applications
        is those who have difficulty reading because of learning disabilities or language barriers. Although
        functionality remains limited
        compared to equivalent desktop applications, the major benefit is to increase the accessibility of said websites
        when viewed on public machines where users do not have permission to install custom software, giving people
        greater "freedom to roam".
    </p>

    <p>
        With the development of smartphones, the ability to listen to written documents (textual web content, PDF
        documents, e-mails etc.) while driving or during a similar activity in the same way that listening to music,
        will benefit a much broader audience
        than visually-impaired people. The best-known examples are Siri for iOS, and Google Now and Iris for Android.
        With the release of the Galaxy S III, Samsung also introduced a similar intelligent personal assistant called S
        Voice. On the BlackBerry
        10 operating system, their Z30 smartphone also features spoken interaction features, which are similar to the
        other mobile operating systems.
    </p>

    <p>
        This functionality depends on the quality of the software but also on a logical structure of the text. Use of
        headings, punctuation, presence of alternate attributes for images, etc. is crucial for a good vocalization.
        Also a web site may have a nice
        look because of the use of appropriate two dimensional positioning with CSS but its standard linearization, for
        example, by suppressing any CSS and Javascript in the browser may not be comprehensible.
    </p>

    <h2 class="level2">
        Customization
    </h2>
    <p>
        Most screen readers allow the user to select whether most punctuation is announced or silently ignored. Some
        screen readers can be tailored to a particular application through scripting. One advantage of scripting is that
        it allows customizations to be
        shared among users, increasing accessibility for all. JAWS enjoys an active script-sharing community, for
        example.
    </p>
    <h3 class="level3">
        Verbosity
    </h3>
    <p>
        Verbosity is a feature of screen reading software that supports vision-impaired computer users. Speech verbosity
        controls enable users to choose how much speech feedback they wish to hear. Specifically, verbosity settings
        allow users to construct a mental
        model of web pages displayed on their computer screen. Based on verbosity settings, a screen-reading program
        informs users of certain formatting changes, such as when a frame or table begins and ends, where graphics have
        been inserted into the
        text, or when a list appears in the document.
    </p>
    <h3 class="level3">
        Language
    </h3>
    <p>
        Some screen readers can read text in more than one language, provided that the language of the material is
        encoded in its metadata.
    </p>
    <p>
        Some screen reading programs also include language verbosity, which automatically detects verbosity settings
        related to speech output language. For example, if a user navigated to a website based in the United Kingdom,
        the text would be read with an English
        accent.
    </p>
    <hr>
    <p>Source: <a href="https://en.wikipedia.org/wiki/Screen_reader">Screen reader</a> by <a
            href="https://en.wikipedia.org">Wikipedia</a> is licensed under <a
            href="https://creativecommons.org/licenses/by/3.0/legalcode">CC BY 3.0</a>
    </p>
</body>

</html>